 CRITICAL ANALYSIS: AI-Enabled Phishing Detection System

**Date:** 2025-10-25
**Status:** ðŸ”´ PRODUCTION NOT READY
**Severity:** CRITICAL

---

## Executive Summary

The AI-enabled phishing detection system has **fundamental architectural and data problems** that prevent it from working as a general-purpose phishing detector. The system was designed for **CSE impersonation detection** (detecting fake versions of specific Indian PSU/bank websites) but is being used for **general phishing detection** - a completely different problem.

**Key Finding:** The model has **ZERO labeled phishing examples** and relies entirely on unsupervised anomaly detection from a narrow baseline of 116 Indian institutional websites.

---

## ðŸ“Š Data Analysis Results

### Dataset Composition (129 domains analyzed)

| Metric | Value | Issue |
|--------|-------|-------|
| **Phishing samples** | 0 (0%) | âŒ Cannot train phishing detection |
| **Benign samples** | 127 (98.4%) | âš ï¸ Severe class imbalance |
| **Suspicious** | 1 (0.8%) | âš ï¸ Unlabeled, unclear ground truth |
| **Government domains** | 23 (17.8%) | â„¹ï¸ Institutional bias |
| **Banking domains** | 30 (23.3%) | â„¹ï¸ Narrow domain focus |

**Critical Issue:** Without phishing examples, the model cannot learn what phishing looks like - it only knows what the CSE baseline looks like.

### CSE Baseline Analysis

- **Size:** 116 domains
- **Composition:** 100% Indian PSUs, banks, government sites
- **Coverage:**
  - âœ… Indian institutional websites
  - âŒ E-commerce sites
  - âŒ Social media
  - âŒ International services
  - âŒ Generic business sites
  - âŒ Personal websites

**Impact:** Any website outside this narrow profile will be flagged as "anomalous"

### Visual Similarity Index

- **Size:** 51 screenshot embeddings
- **Composition:**
  - Banking: 37.3%
  - Other: 41.2%
  - Commercial: 11.8%
  - Government: 9.8%

**Problem:** With only 51 reference images, visual matching has:
- High false positive rate (different layouts match similar colors/structure)
- Low coverage (most legitimate sites not represented)
- Bias toward corporate/institutional designs

---

## âŒ Fundamental Problems

### 1. **NO SUPERVISED LEARNING** (CRITICAL)

**Problem:**
The anomaly detector (IsolationForest) is **unsupervised** - it has never seen labeled phishing examples.

**How it works now:**
```
Training: "Here are 116 Indian PSU/bank websites - this is normal"
Detection: "This website looks different from PSUs â†’ ANOMALY â†’ Maybe phishing?"
```

**What's wrong:**
- Legitimate but unique websites â†’ flagged as anomalies
- Sophisticated phishing (looks like CSE baseline) â†’ passes as normal
- Cannot distinguish phishing patterns from legitimate diversity

**Example failure:**
- Modern startup website with unique design â†’ ANOMALY (false positive)
- Perfect clone of SBI bank â†’ NORMAL (false negative)

---

### 2. **ARCHITECTURE PURPOSE MISMATCH** (CRITICAL)

**What it was designed for:** CSE Impersonation Detection
```
Goal: Detect fake versions of SPECIFIC known websites (SBI, HDFC, etc.)
Method: "Does this claim to be sbi.co.in but looks different from real SBI?"
Baseline: Known-good screenshots of 51 specific organizations
```

**What it's being used for:** General Phishing Detection
```
Goal: Detect ANY phishing website across all domains
Method: "Is this website phishing?" (without knowing what phishing looks like)
Baseline: Same 51 organizations (irrelevant for general detection)
```

**Result:** Square peg, round hole

---

### 3. **FEATURE SCHEMA BREAKDOWN** (HIGH)

**Model expects 42 features:**
```python
# Features the anomaly model was trained on:
- doc_has_login_keywords      âŒ Missing
- doc_has_verify_keywords     âŒ Missing
- doc_has_password_keywords   âŒ Missing
- cert_age_days               âŒ Missing
- ocr_has_login_keywords      âŒ Missing
- (+ 7 more missing)
```

**Crawler provides 92 features:**
```python
# Features crawler actually extracts:
- has_verdict                 âœ“ Different name
- risk_score                  âœ“ Different name
- ocr_text_length             âœ“ Different name
- (but missing the critical keyword detection features)
```

**Impact:**
- 12/42 features (28%) are missing or misnamed
- Model defaults missing features to 0
- All domains look the same on keyword features â†’ poor discrimination

**Root cause:**
- Keyword extraction code exists (`extract_text_features.py`)
- But runs OFFLINE during data prep, not at RUNTIME
- AIML service doesn't call it during live detection

---

### 4. **NO GROUND TRUTH VALIDATION** (HIGH)

**Missing validation infrastructure:**
- âŒ No labeled test set (phishing vs benign)
- âŒ No accuracy/precision/recall metrics
- âŒ No false positive rate measurement
- âŒ No A/B testing framework
- âŒ No model performance monitoring

**Impact:**
- Cannot measure if model is improving or degrading
- Cannot compare different model versions
- Cannot validate fixes work
- Flying blind

---

### 5. **DETECTOR WEIGHT IMBALANCE** (MEDIUM)

**Current ensemble weights:**
```python
'anomaly': 0.20     # Broken (feature mismatch)
'visual': 0.30      # High false positives (small index)
'content': 0.20     # Works, but limited
'domain': 0.15      # Works well, but LOWEST weight
'autoencoder': 0.15 # Works, but limited
```

**Problem:**
- Domain reputation (most reliable) has lowest weight
- Visual similarity (most flawed) has highest weight
- Anomaly detector (broken) still weighted at 20%

**Result:** False positives override correct signals

---

## ðŸŽ¯ What the System CAN Do (Currently)

### âœ… Working Capabilities

1. **CSE Impersonation Detection** (original purpose)
   - Detect typosquatting of known CSE domains
   - Detect visual clones of specific PSU/bank sites
   - Domain reputation analysis for Indian institutions

2. **Rule-Based Detection** (Crawler + Rule-Scorer)
   - SSL certificate validation
   - Form analysis (credential harvesting)
   - JavaScript behavior detection
   - DNS anomaly detection
   - **98.4% accuracy on benign samples** âœ…

3. **Domain Reputation**
   - IDN homograph detection
   - TLD risk analysis
   - Registrar validation
   - Typosquatting detection

### âŒ What It CANNOT Do (Currently)

1. **General Phishing Detection**
   - Detect phishing outside CSE impersonation
   - Identify novel phishing techniques
   - Distinguish sophisticated phishing from legitimate sites

2. **Zero-Day Phishing**
   - Detect new phishing campaigns
   - Identify unseen phishing patterns
   - Adapt to evolving threats

3. **International Phishing**
   - Non-Indian phishing sites
   - Non-PSU/bank targets
   - Different cultural/linguistic patterns

---

## ðŸ” Root Cause Analysis

### Why This Happened

1. **Scope Creep**
   - Started as CSE-specific detector
   - Expanded to general phishing without architectural changes
   - Training data never updated

2. **Data Collection Failure**
   - No phishing sample collection pipeline
   - No labeling infrastructure
   - Relied on unsupervised learning

3. **Offline vs Runtime Gap**
   - Feature extraction exists but runs offline
   - Runtime detection uses incomplete features
   - No integration between data prep and live service

4. **No Validation Loop**
   - Model deployed without accuracy measurement
   - No feedback from false positives/negatives
   - No continuous improvement mechanism

---

## ðŸ“‹ Recommended Solutions

### Option A: Fix for CSE Impersonation (Quick Fix - 2 weeks)

**Keep original scope, fix implementation:**

1. **Fix feature pipeline** (Priority 1)
   - Integrate `TextFeatureExtractor` into runtime
   - Map feature names correctly
   - Validate all 42 features available

2. **Expand CSE baseline** (Priority 2)
   - Add all target organizations (200+ domains)
   - Collect fresh screenshots
   - Rebuild CLIP index

3. **Tune ensemble weights** (Priority 3)
   - Increase domain detector weight to 0.30
   - Decrease visual detector weight to 0.20
   - Add TLD-aware weighting

4. **Add government whitelist** (Priority 4)
   - Skip ML detection for `.gov.in` domains
   - Return BENIGN with high confidence

**Result:** Reliable CSE impersonation detector, not general phishing

---

### Option B: Build General Phishing Detector (Proper Fix - 3 months)

**Redesign for general phishing detection:**

1. **Collect training data** (Weeks 1-4)
   - Phishing samples: 10,000+ from PhishTank, OpenPhish
   - Benign samples: 10,000+ from Alexa Top sites
   - Label quality validation
   - Temporal split (oldâ†’train, recentâ†’test)

2. **Retrain supervised models** (Weeks 5-8)
   - Replace IsolationForest with XGBoost/Random Forest
   - Train on labeled phishing vs benign
   - Feature importance analysis
   - Cross-validation

3. **Build validation pipeline** (Weeks 9-10)
   - Ground truth test set
   - Accuracy/precision/recall metrics
   - ROC curves, confusion matrices
   - False positive analysis

4. **Deploy with monitoring** (Weeks 11-12)
   - A/B testing framework
   - Live performance metrics
   - Feedback loop from misclassifications
   - Continuous retraining

**Result:** Production-ready general phishing detector

---

### Option C: Hybrid Approach (Recommended - 1 month)

**Combine rule-based + narrow ML:**

1. **Prioritize rule-based detection** (Week 1)
   - Rule-scorer is already 98.4% accurate
   - Add more heuristic rules for known patterns
   - Enhance JavaScript analysis
   - Improve form inspection

2. **Use ML for CSE impersonation only** (Week 2)
   - Fix feature pipeline
   - Expand CSE baseline
   - Tune for zero false positives on legitimate sites

3. **Add threat intelligence integration** (Week 3)
   - PhishTank API
   - Google Safe Browsing
   - URLhaus feeds
   - Known phishing domain lists

4. **Build measurement framework** (Week 4)
   - Ground truth test set (manual labeling)
   - Daily accuracy reports
   - False positive tracking
   - User feedback mechanism

**Result:** Reliable detection with measurable performance

---

## ðŸš¨ Immediate Actions Required

### Priority 0 (This Week)

1. **Stop making claims about general phishing detection**
   - System is CSE-impersonation detector, not general phishing
   - Document limitations clearly
   - Set correct expectations

2. **Fix feature pipeline**
   - Integrate `TextFeatureExtractor` at runtime âœ… (partially done)
   - Map all 12 missing features
   - Validate with real data

3. **Add government domain whitelist** âœ… (done)
   - Prevent false positives on `.gov.in`
   - Skip expensive ML for trusted domains

### Priority 1 (Next 2 Weeks)

1. **Collect ground truth test set**
   - 100 known phishing sites
   - 100 known benign sites
   - Manual verification
   - Measure current accuracy

2. **Expand CSE baseline**
   - Add missing target organizations
   - Collect fresh screenshots
   - Rebuild visual index

3. **Build monitoring dashboard**
   - Daily detection statistics
   - Verdict distribution
   - Confidence histograms
   - Alert on anomalies

### Priority 2 (Next Month)

1. **Decide on architecture path**
   - Option A: CSE-only detector
   - Option B: General phishing detector
   - Option C: Hybrid approach

2. **Begin data collection**
   - If going with Option B/C
   - Automated phishing feed ingestion
   - Labeling workflow

3. **Retrain models**
   - With correct features
   - On appropriate data
   - With validation metrics

---

## ðŸ“Š Success Metrics

**If fixing for CSE impersonation (Option A/C):**
- âœ… Zero false positives on CSE baseline domains
- âœ… >95% detection of CSE typosquatting
- âœ… >90% detection of visual clones
- âœ… <1% false positive rate on benign Indian sites

**If building general detector (Option B):**
- âœ… >95% phishing detection rate (TPR)
- âœ… <0.1% false positive rate (FPR)
- âœ… F1 score >0.95
- âœ… Detection within 24h of phishing site creation

---

## Conclusion

The system is **not broken** - it's working as designed. The problem is that it was **designed for CSE impersonation detection** but is being **used for general phishing detection**.

**Key insights:**

1. **Rule-based detection (crawler) works well** (98.4% accuracy on benign)
2. **ML detection is CSE-specific** and shouldn't be applied generally
3. **Feature pipeline has gaps** but can be fixed quickly
4. **No ground truth** means we're flying blind on accuracy
5. **Need to decide:** Fix for original purpose or redesign for new purpose

**Recommendation:** **Option C (Hybrid)** - prioritize rule-based detection, fix ML for CSE-only, add threat intelligence, and build measurement infrastructure.

---

## Next Steps

1. **Review this analysis** with stakeholders
2. **Choose architecture path** (A, B, or C)
3. **Allocate resources** based on chosen path
4. **Begin immediate fixes** (Priority 0 items)
5. **Set realistic timeline** for production readiness

**Current Status:** Not production-ready for general phishing detection
**Estimated Time to Production:** 1-3 months depending on chosen path
**Blocker:** Need labeled phishing dataset and validation framework
